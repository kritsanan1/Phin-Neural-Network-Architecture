# Phin Neural Network Architecture

## ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

### ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢ "‡∏û‡∏¥‡∏ì"

‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÑ‡∏ó‡∏¢ "‡∏û‡∏¥‡∏ì" ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏û‡∏ô‡πÅ‡∏ó‡∏ó‡∏≠‡∏ô‡∏¥‡∏Å (5 ‡πÄ‡∏™‡∏µ‡∏¢‡∏á) ‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢

#### ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å

üéµ **‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏û‡∏ô‡πÅ‡∏ó‡∏ó‡∏≠‡∏ô‡∏¥‡∏Å (Pentatonic Scale System)**
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö 5 ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏û‡∏¥‡∏ì
- ‡∏Ñ‡∏µ‡∏¢‡πå‡∏´‡∏•‡∏±‡∏Å: A minor pentatonic (A, C, D, E, G)
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 7 ‡πÅ‡∏ö‡∏ö

ü•Å **‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡πÑ‡∏ó‡∏¢**
- ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏° 8 ‡πÅ‡∏ö‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏≥‡∏â‡∏±‡∏ô‡∏ó‡πå, ‡∏ä‡∏±‡∏á‡∏´‡∏ß‡πà‡∏≤, ‡πÇ‡∏õ‡∏á‡∏•‡∏≤‡∏á
- ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞
- ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡πà‡∏≤ BPM ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

üé® **‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô**
- ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏û‡∏¥‡∏ì 16 ‡πÅ‡∏ö‡∏ö ‡πÄ‡∏ä‡πà‡∏ô bend, slide, hammer-on, vibrato
- ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå MIDI
- ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô

üß† **‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó**
- Custom embedding layer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏û‡∏ô‡πÅ‡∏ó‡∏ó‡∏≠‡∏ô‡∏¥‡∏Å
- Attention mechanism ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞
- Encoder-decoder ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏∞‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î
- Multi-task learning: ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏ô‡πâ‡∏ï, ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ, ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞, ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î

## English

### Specialized Neural Network Architecture for Thai "Phin" Instrument

This architecture is specifically designed for analyzing and generating music for the Thai "Phin" instrument, considering the unique characteristics of the pentatonic scale system (5 notes) and traditional Thai rhythmic patterns.

#### Key Features

üéµ **Pentatonic Scale System**
- Supports traditional 5-note system of Phin
- Primary key: A minor pentatonic (A, C, D, E, G)
- Supports all 7 modal variations

ü•Å **Thai Rhythmic Pattern Recognition**
- 8 traditional rhythmic patterns such as Samchan, Changwa, Ponglang
- Rhythmic pattern similarity analysis
- Automatic BPM estimation

üé® **Playing Technique Recognition**
- 16 Phin playing techniques such as bend, slide, hammer-on, vibrato
- Detection from MIDI analysis
- Technique sequence generation for training

üß† **Neural Network Architecture**
- Custom embedding layer for pentatonic system
- Attention mechanism for rhythmic patterns
- Scale/mode-aware encoder-decoder
- Multi-task learning: note, technique, rhythm, and mode prediction

## Installation

```bash
# Install dependencies
pip install torch torchvision torchaudio
pip install pretty_midi music21 librosa
pip install numpy pandas matplotlib seaborn scikit-learn

# Clone or download the package files
# phin_neural_network.py
# phin_data_preprocessing.py  
# phin_training_framework.py
# phin_ai_package.py
```

## Quick Start

```python
from phin_ai_package import PhinAIModel, quick_train

# Create and train model
phin_ai = PhinAIModel()
phin_ai.build_model()

# Preprocess MIDI data
phin_ai.preprocess_data("midi_folder", "dataset.json")

# Generate music
seed_notes = [60, 62, 64, 65, 67]  # A minor pentatonic seed
generated = phin_ai.generate_music(seed_notes, max_length=128)

# Analyze MIDI file
features = phin_ai.analyze_midi("phin_music.mid", scale_type="A_minor")
```

## Architecture Details

### Core Components

1. **PhinPentatonicEmbedding**
   - Custom embedding layer with pentatonic bias
   - Position embeddings for sequence information
   - Supports all 12 MIDI note numbers with pentatonic emphasis

2. **PhinRhythmAttention**
   - Multi-head attention mechanism
   - Rhythm pattern recognition and bias
   - Supports 8 traditional Thai rhythmic patterns

3. **PhinTechniqueEncoder**
   - LSTM-based technique sequence processing
   - 16 different playing techniques
   - Technique embedding and classification

4. **PhinScaleAwareDecoder**
   - Mode-aware decoding (7 modes)
   - Pentatonic constraint enforcement
   - Scale-specific note probability adjustment

### Model Specifications

- **Input**: MIDI note sequences (128 vocab size)
- **Embedding Dimension**: 256 (configurable)
- **Attention Heads**: 8
- **Layers**: 6 transformer layers
- **Output**: Next note prediction, technique classification, rhythm analysis, mode prediction

### Loss Functions

- **Note Prediction**: Cross-entropy loss
- **Technique Classification**: Cross-entropy loss  
- **Rhythm Analysis**: MSE loss for pattern matching
- **Mode Prediction**: Cross-entropy loss
- **Pentatonic Constraint**: Custom penalty for non-pentatonic notes

## Dataset Structure

The system expects MIDI files with Phin music in A minor pentatonic scale. The preprocessing pipeline extracts:

- **Pentatonic Features**: Ratio of notes within pentatonic scale
- **Rhythmic Patterns**: 8-beat pattern classification
- **Playing Techniques**: 16 different technique types
- **Metadata**: Tempo, time signature, style information

Example dataset entry:
```json
{
  "metadata": {
    "lai_name": "‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏á‡∏•‡∏≤‡∏á",
    "scale": "A_minor_pentatonic", 
    "tempo": 120,
    "time_signature": "4/4"
  },
  "notation": {
    "midi_file": "ponglang_01.mid",
    "notes": [60, 62, 64, 65, 67, 69, 71, 72],
    "techniques": [0, 1, 0, 2, 0, 1, 0, 3]
  }
}
```

## Training Process

1. **Data Preprocessing**: Convert MIDI files to training sequences
2. **Model Initialization**: Build neural network with specified architecture
3. **Training Loop**: Multi-task learning with custom loss function
4. **Validation**: Evaluate on held-out test set
5. **Generation**: Use trained model for music generation

## Performance Metrics

- **Note Accuracy**: Percentage of correctly predicted notes
- **Technique Accuracy**: Classification accuracy for playing techniques
- **Rhythm Similarity**: Pattern matching score for rhythmic analysis
- **Pentatonic Adherence**: Constraint satisfaction for pentatonic scale

## Applications

üéº **Music Generation**: Create new Phin music in traditional style
üìä **Music Analysis**: Extract features from existing Phin recordings  
üéì **Educational Tool**: Help students learn traditional patterns
üíæ **Cultural Preservation**: Digitally preserve traditional music
üîÑ **Fusion Music**: Combine Phin with other musical styles

## Traditional Thai Music Integration

The architecture specifically handles:

- **Lai (‡∏•‡∏≤‡∏¢)**: Traditional melodic patterns
- **Thang (‡∏ó‡∏≤‡∏á)**: Playing styles and techniques
- **Pitas (‡∏û‡∏¥‡∏©)**: Rhythmic cycles
- **Kratai (‡∏Å‡∏£‡∏∞‡∏ó‡πà‡∏≠‡∏°)**: Structural forms

Supported traditional patterns:
- ‡∏•‡∏≤‡∏¢‡∏•‡∏≥‡πÄ‡∏û‡∏•‡∏¥‡∏ô (Lai Lam Phloen)
- ‡∏•‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡∏™‡∏∞‡πÅ‡∏ô‡∏ô (Lai Sut Sa Nen)  
- ‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏á‡∏•‡∏≤‡∏á (Lai Ponglang)
- ‡∏•‡∏≤‡∏¢‡∏†‡∏π‡πÑ‡∏ó (Lai Phu Thai)
- ‡∏•‡∏≤‡∏¢‡πÄ‡∏ã‡∏¥‡πâ‡∏á‡∏ö‡∏±‡πâ‡∏á‡πÑ‡∏ü (Lai Seng Bang Fai)

## Research and Development

This architecture is designed for:

1. **Cultural Musicology Research**: Analyze traditional music patterns
2. **AI Music Generation**: Create culturally appropriate music
3. **Music Education**: Interactive learning systems
4. **Digital Preservation**: Archive traditional performances
5. **Cross-cultural Fusion**: Combine with other musical traditions

## Future Enhancements

- **Audio-to-MIDI**: Direct audio processing
- **Real-time Generation**: Live performance support
- **Multi-instrument**: Expand to other Thai instruments
- **Style Transfer**: Convert between different regional styles
- **Interactive Learning**: Real-time feedback for students

## Citation

If you use this architecture in your research, please cite:

```bibtex
@software{phin_neural_network_2024,
  title={Phin Neural Network Architecture: Specialized AI for Thai Traditional Music},
  author={AI Assistant},
  year={2024},
  url={https://github.com/your-repo/phin-neural-network}
}
```

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Thai musicologists and cultural experts
- Traditional Phin masters and performers  
- Academic institutions studying Thai music
- Open source music processing libraries
- AI/ML research community

---

**Note**: This is a specialized architecture designed specifically for the Thai "Phin" instrument and its unique musical characteristics. For general music generation, consider using more general-purpose architectures like Music Transformer or MuseNet.